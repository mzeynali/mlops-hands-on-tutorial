version: "3"
services:
    prediction_api:
        build: .
        container_name: "inference_container"
        ports:
            - "8000:8000"